{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\aaani\\OneDrive - Birmingham City University\\Postgrad\\Dissertation\\Data'\n",
    "df = pd.read_csv(f'{data_path}/final_dataset.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display all columns, to be able to asses the na values\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_values_df = pd.DataFrame({\n",
    "    'missing_count': missing_counts,\n",
    "})\n",
    "\n",
    "print(missing_values_df.sort_values(by='missing_count', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising dfs\n",
    "\n",
    "#hospital\n",
    "admissions = pd.read_csv(f'{data_path}/admissions.csv.gz', usecols=admissions_cols)\n",
    "patients = pd.read_csv(f'{data_path}/patients.csv.gz')\n",
    "diagnoses = pd.read_csv(f'{data_path}/diagnoses_icd.csv.gz', usecols=diagnoses_cols)\n",
    "d_icd_diagnoses = pd.read_csv(f'{data_path}/d_icd_diagnoses.csv.gz', usecols=d_icd_diagnoses_cols)\n",
    "d_labitems = pd.read_csv(f'{data_path}/d_labitems.csv.gz', usecols=d_labitems_cols)\n",
    "lab = pd.read_csv(f'{data_path}/labevents_last24h.csv.gz', usecols=labevents_cols, parse_dates=['charttime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#icu\n",
    "icustays = pd.read_csv(f'{data_path}/icustays.csv.gz', usecols=icustays_cols, parse_dates=['outtime'])\n",
    "chartevents = pd.read_csv(f'{data_path}/chartevents_last24h.csv.gz', parse_dates=['charttime'], usecols=chartevents_cols)\n",
    "d_items = pd.read_csv(f'{data_path}/d_items.csv.gz', usecols=d_items_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 10_000_000\n",
    "\n",
    "# This flag ensures we only write the header once\n",
    "first_chunk = True\n",
    "\n",
    "# Create a loop that reads the massive labevents file in small chunks\n",
    "for chunk in pd.read_csv(f'{data_path}/labevents.csv.gz', chunksize=chunk_size, parse_dates=['charttime']):\n",
    "    \n",
    "    # Merge the chunk with admissions to get the 'dischtime' for each lab event\n",
    "    chunk_with_dischtime = pd.merge(chunk, admissions, on=['subject_id', 'hadm_id'], how='inner')\n",
    "    \n",
    "    # Calculate the time difference in hours from the lab event to hospital discharge\n",
    "    time_delta_hours = (chunk_with_dischtime['dischtime'] - chunk_with_dischtime['charttime']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Filter the chunk to keep only labs from the last 24 hours before discharge\n",
    "    filtered_chunk = chunk_with_dischtime[(time_delta_hours >= 0) & (time_delta_hours <= 24)]\n",
    "    \n",
    "    # If the filtered chunk contains any data, save it to our new CSV file\n",
    "    if not filtered_chunk.empty:\n",
    "        if first_chunk:\n",
    "            # For the first chunk, create a new file ('mode=w') and write the header\n",
    "            filtered_chunk.to_csv('labevents_last24h.csv', index=False, mode='w', header=True)\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            # For all subsequent chunks, append ('mode=a') to the file without the header\n",
    "            filtered_chunk.to_csv('labevents_last24h.csv', index=False, mode='a', header=False)\n",
    "            \n",
    "    print(f\"Processed a chunk of {chunk_size} rows...\")\n",
    "\n",
    "print(\"\\nFinished processing labevents. A new, much smaller file 'labevents_last24h.csv' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 10_000_000 # 10 million rows at a time\n",
    "\n",
    "# This flag ensures we only write the header once\n",
    "first_chunk = True\n",
    "\n",
    "# Create a loop that reads the massive chartevents file in small chunks\n",
    "for chunk in pd.read_csv(f'{data_path}/chartevents.csv.gz', chunksize=chunk_size, parse_dates=['charttime']):\n",
    "    \n",
    "    # Merge the chunk with icustays to get the 'outtime' for each event\n",
    "    chunk_with_outtime = pd.merge(chunk, icustays, on=['subject_id', 'hadm_id', 'stay_id'], how='inner')\n",
    "    \n",
    "    # Calculate the time difference in hours from the event to ICU discharge\n",
    "    time_delta_hours = (chunk_with_outtime['outtime'] - chunk_with_outtime['charttime']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Filter the chunk to keep only events from the last 24 hours before ICU discharge\n",
    "    filtered_chunk = chunk_with_outtime[(time_delta_hours >= 0) & (time_delta_hours <= 24)]\n",
    "    \n",
    "    # If the filtered chunk contains any data, save it to our new CSV file\n",
    "    if not filtered_chunk.empty:\n",
    "        if first_chunk:\n",
    "            # For the first chunk, create a new .gz file and write the header\n",
    "            filtered_chunk.to_csv(\n",
    "                'chartevents_last24h.csv.gz', \n",
    "                index=False, \n",
    "                mode='w', \n",
    "                header=True, \n",
    "                compression='gzip'\n",
    "            )\n",
    "            first_chunk = False\n",
    "    else:\n",
    "        # For all subsequent chunks, append to the .gz file without the header\n",
    "        filtered_chunk.to_csv(\n",
    "            'chartevents_last24h.csv.gz', \n",
    "            index=False, \n",
    "            mode='a', \n",
    "            header=False, \n",
    "            compression='gzip'\n",
    "        )\n",
    "            \n",
    "    print(f\"Processed a chunk of {chunk_size} rows...\")\n",
    "\n",
    "print(\"\\nFinished processing chartevents. A new, much smaller file 'chartevents_last24h.csv.gz' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop values where valuenum is null\n",
    "lab= lab.dropna(subset=['valuenum'])\n",
    "chartevents = chartevents.dropna(subset=['valuenum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6599888 entries, 0 to 6599887\n",
      "Columns: 137 entries, subject_id to max_Temperature Fahrenheit\n",
      "dtypes: datetime64[ns](1), float64(124), int64(5), object(7)\n",
      "memory usage: 6.7+ GB\n"
     ]
    }
   ],
   "source": [
    "# merged patients to multiple links patient to their diagnoses, lab results, and ICU stays\n",
    "\n",
    "# used left joins on all so no data is lost\n",
    "\n",
    "# merged patients with their hospital admissions\n",
    "merged = pd.merge(admissions, patients, on='subject_id', how='left')\n",
    "\n",
    "# merge icd codes with their descriptions\n",
    "diag = pd.merge(diagnoses, d_icd_diagnoses, on=['icd_code', 'icd_version'], how='left')\n",
    "merged = pd.merge(merged, diag, on= ['subject_id' , 'hadm_id'], how='left') #back to the main merge\n",
    "\n",
    "# icu stay info\n",
    "merged = pd.merge(merged, icustays, on=['subject_id' , 'hadm_id'], how='left')\n",
    "\n",
    "# add labels to lab events\n",
    "lab = pd.merge(lab, d_labitems, on='itemid', how='left')\n",
    "chartevents = pd.merge(chartevents, d_items, on='itemid', how='left')\n",
    "\n",
    "top_20_labs = lab['label'].value_counts().nlargest(20).index #20 most common lab tests\n",
    "lab_filtered = lab[lab['label'].isin(top_20_labs)] #new fd that onlt has the top 20 lab results - smaller size\n",
    "\n",
    "lab_features = lab_filtered.groupby(['hadm_id', 'label'])['valuenum'].agg(['mean', 'min', 'max']).unstack(level='label')\n",
    "lab_features.columns = ['_'.join(col).strip() for col in lab_features.columns.values]\n",
    "lab_features = lab_features.reset_index()\n",
    "\n",
    "top_20_charts = chartevents['label'].value_counts().nlargest(20).index # 20 most common chart events\n",
    "charts_filtered = chartevents[chartevents['label'].isin(top_20_charts)]\n",
    "\n",
    "chartevents_features = charts_filtered.groupby(['stay_id', 'label'])['valuenum'].agg(['mean', 'min', 'max']).unstack(level='label')\n",
    "\n",
    "chartevents_features.columns = ['_'.join(col).strip() for col in chartevents_features.columns.values]\n",
    "chartevents_features = chartevents_features.reset_index()\n",
    "\n",
    "merged = pd.merge(merged, lab_features, on=['hadm_id'], how='left')\n",
    "merged = pd.merge(merged, chartevents_features, on=['stay_id'], how='left')\n",
    "\n",
    "merged.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('final_dataset.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv(f'{data_path}/final_dataset.csv.gz', nrows=1)\n",
    "\n",
    "\n",
    "df = pd.read_csv(f'{data_path}/final_dataset.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            missing_count\n",
      "min_Arterial Blood Pressure systolic              6590790\n",
      "max_Arterial Blood Pressure systolic              6590790\n",
      "max_Arterial Blood Pressure diastolic             6590790\n",
      "mean_Arterial Blood Pressure diastolic            6590790\n",
      "mean_Arterial Blood Pressure systolic             6590790\n",
      "min_Arterial Blood Pressure diastolic             6590790\n",
      "min_Arterial Blood Pressure mean                  6590696\n",
      "mean_Arterial Blood Pressure mean                 6590696\n",
      "max_Arterial Blood Pressure mean                  6590696\n",
      "min_Orientation                                   6581297\n",
      "max_Orientation                                   6581297\n",
      "mean_Orientation                                  6581297\n",
      "mean_Activity / Mobility (JH-HLM)                 6575301\n",
      "min_Activity / Mobility (JH-HLM)                  6575301\n",
      "max_Activity / Mobility (JH-HLM)                  6575301\n",
      "min_Strength L Arm                                6570006\n",
      "mean_Strength L Arm                               6570006\n",
      "max_Strength L Arm                                6570006\n",
      "min_ST Segment Monitoring On                      6568507\n",
      "max_ST Segment Monitoring On                      6568507\n",
      "mean_ST Segment Monitoring On                     6568507\n",
      "min_Richmond-RAS Scale                            6563544\n",
      "mean_Richmond-RAS Scale                           6563544\n",
      "max_Richmond-RAS Scale                            6563544\n",
      "max_Non Invasive Blood Pressure mean              6561439\n",
      "mean_Non Invasive Blood Pressure mean             6561439\n",
      "min_Non Invasive Blood Pressure mean              6561439\n",
      "mean_Non Invasive Blood Pressure diastolic        6561413\n",
      "min_Non Invasive Blood Pressure diastolic         6561413\n",
      "max_Non Invasive Blood Pressure diastolic         6561413\n",
      "max_Non Invasive Blood Pressure systolic          6561404\n",
      "min_Non Invasive Blood Pressure systolic          6561404\n",
      "mean_Non Invasive Blood Pressure systolic         6561404\n",
      "mean_Temperature Fahrenheit                       6561001\n",
      "min_Temperature Fahrenheit                        6561001\n",
      "max_Temperature Fahrenheit                        6561001\n",
      "max_Parameters Checked                            6560489\n",
      "min_Parameters Checked                            6560489\n",
      "mean_Parameters Checked                           6560489\n",
      "min_Alarms On                                     6560252\n",
      "max_Alarms On                                     6560252\n",
      "mean_Alarms On                                    6560252\n",
      "max_GCS - Motor Response                          6559944\n",
      "mean_GCS - Motor Response                         6559944\n",
      "min_GCS - Motor Response                          6559944\n",
      "max_GCS - Verbal Response                         6559911\n",
      "mean_GCS - Verbal Response                        6559911\n",
      "min_GCS - Verbal Response                         6559911\n",
      "max_GCS - Eye Opening                             6559868\n",
      "mean_GCS - Eye Opening                            6559868\n",
      "min_GCS - Eye Opening                             6559868\n",
      "max_Respiratory Rate                              6559548\n",
      "min_Respiratory Rate                              6559548\n",
      "mean_Respiratory Rate                             6559548\n",
      "min_O2 saturation pulseoxymetry                   6559536\n",
      "mean_O2 saturation pulseoxymetry                  6559536\n",
      "max_O2 saturation pulseoxymetry                   6559536\n",
      "mean_Heart Rate                                   6559463\n",
      "max_Heart Rate                                    6559463\n",
      "min_Heart Rate                                    6559463\n",
      "outtime                                           4840963\n",
      "los                                               4840963\n",
      "stay_id                                           4840622\n",
      "dod                                               4131305\n",
      "min_Calcium, Total                                3077461\n",
      "mean_Calcium, Total                               3077461\n",
      "max_Calcium, Total                                3077461\n",
      "max_Phosphate                                     3073839\n",
      "mean_Phosphate                                    3073839\n",
      "min_Phosphate                                     3073839\n",
      "mean_Magnesium                                    2809659\n",
      "max_Magnesium                                     2809659\n",
      "min_Magnesium                                     2809659\n",
      "mean_RDW                                          2508577\n",
      "min_RDW                                           2508577\n",
      "max_RDW                                           2508577\n",
      "mean_MCH                                          2505158\n",
      "min_MCH                                           2505158\n",
      "max_MCH                                           2505158\n",
      "max_MCV                                           2505140\n",
      "mean_MCV                                          2505140\n",
      "min_MCV                                           2505140\n",
      "max_Red Blood Cells                               2505108\n",
      "mean_Red Blood Cells                              2505108\n",
      "min_Red Blood Cells                               2505108\n",
      "min_MCHC                                          2504936\n",
      "max_MCHC                                          2504936\n",
      "mean_MCHC                                         2504936\n",
      "min_White Blood Cells                             2498157\n",
      "mean_White Blood Cells                            2498157\n",
      "max_White Blood Cells                             2498157\n",
      "max_Hemoglobin                                    2491858\n",
      "min_Hemoglobin                                    2491858\n",
      "mean_Hemoglobin                                   2491858\n",
      "min_Platelet Count                                2477312\n",
      "max_Platelet Count                                2477312\n",
      "mean_Platelet Count                               2477312\n",
      "mean_Glucose                                      2447191\n",
      "max_Glucose                                       2447191\n",
      "min_Glucose                                       2447191\n",
      "max_Anion Gap                                     2428360\n",
      "min_Anion Gap                                     2428360\n",
      "mean_Anion Gap                                    2428360\n",
      "mean_Bicarbonate                                  2426632\n",
      "min_Bicarbonate                                   2426632\n",
      "max_Bicarbonate                                   2426632\n",
      "mean_Hematocrit                                   2400299\n",
      "min_Hematocrit                                    2400299\n",
      "max_Hematocrit                                    2400299\n",
      "max_Chloride                                      2380449\n",
      "min_Chloride                                      2380449\n",
      "mean_Chloride                                     2380449\n",
      "mean_Sodium                                       2361563\n",
      "max_Sodium                                        2361563\n",
      "min_Sodium                                        2361563\n",
      "min_Urea Nitrogen                                 2348959\n",
      "mean_Urea Nitrogen                                2348959\n",
      "max_Urea Nitrogen                                 2348959\n",
      "min_Potassium                                     2327086\n",
      "mean_Potassium                                    2327086\n",
      "max_Potassium                                     2327086\n",
      "mean_Creatinine                                   2326754\n",
      "max_Creatinine                                    2326754\n",
      "min_Creatinine                                    2326754\n",
      "icd_code                                              531\n",
      "seq_num                                               531\n",
      "icd_version                                           531\n",
      "anchor_year                                             0\n",
      "hadm_id                                                 0\n",
      "subject_id                                              0\n",
      "anchor_age                                              0\n",
      "gender                                                  0\n",
      "hospital_expire_flag                                    0\n",
      "race                                                    0\n",
      "dischtime                                               0\n",
      "admittime                                               0\n",
      "anchor_year_group                                       0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_values_df = pd.DataFrame({\n",
    "    'missing_count': missing_counts,\n",
    "})\n",
    "\n",
    "print(missing_values_df.sort_values(by='missing_count', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admittime is a datetime object\n",
    "merged['admittime'] = pd.to_datetime(merged['admittime'])\n",
    "\n",
    "# For each patient, find the year of their first shifted admission\n",
    "first_admission_year_shifted = merged.groupby('subject_id')['admittime'].min().dt.year\n",
    "\n",
    "# Map the earliest shifted year back to every admission for each patient\n",
    "merged['first_admission_year_shifted'] = merged['subject_id'].map(first_admission_year_shifted)\n",
    "\n",
    "# Calculate the unique date shift for each patient\n",
    "merged['date_shift'] = merged['first_admission_year_shifted'] - merged['anchor_year']\n",
    "\n",
    "# Create true_admission_year column by subtracting the shift\n",
    "merged['true_admission_year'] = merged['admittime'].dt.year - merged['date_shift']\n",
    "\n",
    "merged['age_at_admission'] = merged['anchor_age'] + (merged['true_admission_year'] - merged['anchor_year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataset that removes duplicate patients, for analysis\n",
    "unique = merged.drop_duplicates(subset=['subject_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "sns.histplot(unique['age_at_admission'], bins=30, kde=True, color='skyblue')\n",
    "\n",
    "\n",
    "plt.title('Distribution of Patient Age at Admission in MIMIC-IV', fontsize=16)\n",
    "plt.xlabel('Age at Admission', fontsize=12)\n",
    "plt.ylabel('Number of Admissions', fontsize=12)\n",
    "\n",
    "# Saving the plot as an image file \n",
    "plt.savefig('age_distribution.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying unique anchor years\n",
    "unique_anchor_years = unique['anchor_year_group'].unique()\n",
    "unique_anchor_years.sort()\n",
    "print(\"Unique Anchor Years:\", unique_anchor_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_groups = ['2008 - 2010', '2011 - 2013', '2014 - 2016']\n",
    "contemporary_groups = ['2017 - 2019', '2020 - 2022']\n",
    "\n",
    "historical = unique[unique['anchor_year_group'].isin(historical_groups)]\n",
    "contemporary = unique[unique['anchor_year_group'].isin(contemporary_groups)]\n",
    "\n",
    "historical_age_distribution = historical['age_at_admission'].describe()\n",
    "contemporary_age_distribution = contemporary['age_at_admission'].describe()\n",
    "\n",
    "print(\"Historical Age Distribution:\\n\", historical_age_distribution)\n",
    "print(\"\\nContemporary Age Distribution:\\n\", contemporary_age_distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a figure for the plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot the distribution of age for the historical cohort\n",
    "sns.kdeplot(historical['age_at_admission'], label='Historical Cohort (2008-2016)', color='blue', fill=True, alpha=0.5)\n",
    "\n",
    "# Plot the distribution of age for the contemporary cohort on the same axes\n",
    "sns.kdeplot(contemporary['age_at_admission'], label='Contemporary Cohort (2017-2022)', color='green', fill=True, alpha=0.5)\n",
    "\n",
    "# Add titles, labels, and a legend\n",
    "plt.title('Comparison of Patient Age Distribution: Historical vs. Contemporary', fontsize=16)\n",
    "plt.xlabel('Age at Admission', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('age_distribution_comparison.png')\n",
    "\n",
    "#This is important as it provided visual evidence of a data drift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the unique race categories\n",
    "unique_race = unique['race'].unique()\n",
    "unique_race.sort()\n",
    "print(\"Unique Race Categories:\", unique_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for the race categories for better readability\n",
    "\n",
    "race_mapping = {\n",
    "    'ASIAN - ASIAN INDIAN': 'ASIAN',\n",
    "    'ASIAN - CHINESE': 'ASIAN',\n",
    "    'ASIAN - KOREAN': 'ASIAN',\n",
    "    'ASIAN - SOUTH EAST ASIAN': 'ASIAN',\n",
    "    'BLACK/AFRICAN': 'BLACK',\n",
    "    'BLACK/AFRICAN AMERICAN': 'BLACK',\n",
    "    'BLACK/CAPE VERDEAN': 'BLACK',\n",
    "    'BLACK/CARIBBEAN ISLAND': 'BLACK',\n",
    "    'HISPANIC OR LATINO': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - CENTRAL AMERICAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - COLUMBIAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - CUBAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - DOMINICAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - GUATEMALAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - HONDURAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - MEXICAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - PUERTO RICAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - SALVADORAN': 'HISPANIC/LATINO',\n",
    "    'WHITE - BRAZILIAN': 'WHITE',\n",
    "    'WHITE - EASTERN EUROPEAN': 'WHITE',\n",
    "    'WHITE - OTHER EUROPEAN': 'WHITE',\n",
    "    'WHITE - RUSSIAN': 'WHITE',\n",
    "    'PORTUGUESE': 'WHITE',\n",
    "    'SOUTH AMERICAN': 'HISPANIC/LATINO',\n",
    "    'UNABLE TO OBTAIN': 'OTHER/UNKNOWN',\n",
    "    'UNKNOWN': 'OTHER/UNKNOWN',\n",
    "    'PATIENT DECLINED TO ANSWER': 'OTHER/UNKNOWN',\n",
    "    'OTHER': 'OTHER/UNKNOWN',\n",
    "    'AMERICAN INDIAN/ALASKA NATIVE': 'OTHER/UNKNOWN',\n",
    "    'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER': 'OTHER/UNKNOWN',\n",
    "    'MULTIPLE RACE/ETHNICITY': 'OTHER/UNKNOWN'\n",
    "}\n",
    "\n",
    "unique = merged.drop_duplicates(subset=['subject_id']).copy()\n",
    "\n",
    "unique['race_grouped'] = unique['race'].replace(race_mapping)\n",
    "print(unique['race_grouped'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = unique[unique['anchor_year_group'].isin(historical_groups)]\n",
    "contemporary = unique[unique['anchor_year_group'].isin(contemporary_groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage distribution for the historical cohort\n",
    "historical_race_dist = historical['race_grouped'].value_counts(normalize=True).mul(100).rename('percentage').reset_index()\n",
    "historical_race_dist['Cohort'] = 'Historical (2008-2016)'\n",
    "\n",
    "# Calculate the percentage distribution for the contemporary cohort\n",
    "contemporary_race_dist = contemporary['race_grouped'].value_counts(normalize=True).mul(100).rename('percentage').reset_index()\n",
    "contemporary_race_dist['Cohort'] = 'Contemporary (2017-2022)'\n",
    "\n",
    "\n",
    "combined_race_dist = pd.concat([historical_race_dist, contemporary_race_dist])\n",
    "\n",
    "# Visualisation \n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create the bar plot\n",
    "barplot = sns.barplot(data=combined_race_dist, x='race_grouped', y='percentage', hue='Cohort', palette='viridis')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Comparison of Patient Race Distribution: Historical vs. Contemporary', fontsize=16)\n",
    "plt.xlabel('Race', fontsize=12)\n",
    "plt.ylabel('Percentage of Patients (%)', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('race_distribution_comparison.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
