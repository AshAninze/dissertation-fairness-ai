{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\aaani\\OneDrive - Birmingham City University\\Postgrad\\Dissertation\\Data'\n",
    "#df = pd.read_csv(f'{data_path}/final_dataset.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = pd.read_csv(f'{data_path}/historical_cohort.csv.gz')\n",
    "contemporary = pd.read_csv(f'{data_path}/contemporary_cohort.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to prevent data leakage\n",
    "historical_groups = ['2008 - 2010', '2011 - 2013', '2014 - 2016']\n",
    "contemporary_groups = ['2017 - 2019', '2020 - 2022']\n",
    "\n",
    "historical = df[df['anchor_year_group'].isin(historical_groups)]\n",
    "contemporary = df[df['anchor_year_group'].isin(contemporary_groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display all columns, to be able to asses the na values\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "missing_counts = historical.isnull().sum()\n",
    "missing_values_df = pd.DataFrame({\n",
    "    'missing_count': missing_counts,\n",
    "})\n",
    "\n",
    "print(missing_values_df.sort_values(by='missing_count', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = contemporary.isnull().sum()\n",
    "missing_values_df = pd.DataFrame({\n",
    "    'missing_count': missing_counts,\n",
    "})\n",
    "\n",
    "print(missing_values_df.sort_values(by='missing_count', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new feature 'admitted_to_icu' to indicate if a patient was admitted to ICU during their hospital stay\n",
    "historical['admitted_to_icu']= historical['stay_id'].notnull().astype(int)\n",
    "contemporary['admitted_to_icu']= contemporary['stay_id'].notnull().astype(int)\n",
    "\n",
    "#any empty stay ids are filled with 0\n",
    "historical['stay_id'] = historical['stay_id'].fillna(0).astype(int)\n",
    "contemporary['stay_id'] = contemporary['stay_id'].fillna(0).astype(int)\n",
    "\n",
    "#calculate length of stay for hospital \n",
    "historical['admittime'] = pd.to_datetime(historical['admittime'])# ensure column is in datetime format\n",
    "historical['dischtime'] = pd.to_datetime(historical['dischtime']) # type: ignore\n",
    "\n",
    "contemporary['admittime'] = pd.to_datetime(contemporary['admittime'])\n",
    "contemporary['dischtime'] = pd.to_datetime(contemporary['dischtime'])\n",
    "\n",
    "historical['hospital_los'] = (historical['dischtime'] - historical['admittime']).dt.total_seconds() / (24 * 3600)\n",
    "contemporary['hospital_los'] = (contemporary['dischtime'] - contemporary['admittime']).dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "# Fill missing ICU length of stay values with 0\n",
    "historical['los'] = historical['los'].fillna(0)\n",
    "contemporary['los'] = contemporary['los'].fillna(0)\n",
    "\n",
    "\n",
    "missing_diagnoses_df = historical[historical['icd_code'].isnull() & historical['icd_version'].isnull()]\n",
    "print(f\"Found {len(missing_diagnoses_df)} rows with missing ICD codes.\")\n",
    "missing_diagnoses_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with high missing values \n",
    "cols_to_drop = [\n",
    "    'max_Arterial Blood Pressure systolic', 'mean_Arterial Blood Pressure mean', \n",
    "    'mean_Arterial Blood Pressure systolic', 'min_Arterial Blood Pressure diastolic', \n",
    "    'min_Arterial Blood Pressure systolic', 'min_Arterial Blood Pressure mean', \n",
    "    'max_Arterial Blood Pressure diastolic', 'max_Arterial Blood Pressure mean', \n",
    "    'mean_Arterial Blood Pressure diastolic', 'max_Orientation', 'min_Orientation', \n",
    "    'mean_Orientation', 'min_Strength L Arm', 'mean_Strength L Arm', \n",
    "    'max_Strength L Arm', 'mean_ST Segment Monitoring On', 'max_ST Segment Monitoring On', \n",
    "    'min_ST Segment Monitoring On', 'mean_Temperature Fahrenheit', 'min_Temperature Fahrenheit', \n",
    "    'max_Temperature Fahrenheit', 'min_Non Invasive Blood Pressure mean', 'max_Non Invasive Blood Pressure mean', \n",
    "    'mean_Non Invasive Blood Pressure mean', 'mean_Non Invasive Blood Pressure systolic', \n",
    "    'max_Non Invasive Blood Pressure diastolic', 'max_Non Invasive Blood Pressure systolic', \n",
    "    'mean_Non Invasive Blood Pressure diastolic', 'min_Non Invasive Blood Pressure diastolic', \n",
    "    'min_Non Invasive Blood Pressure systolic', 'mean_Parameters Checked', 'max_Parameters Checked', \n",
    "    'min_Parameters Checked', 'max_Alarms On', 'mean_Alarms On', 'min_Alarms On', \n",
    "    'max_Richmond-RAS Scale', 'mean_Richmond-RAS Scale', 'min_Richmond-RAS Scale', \n",
    "    'max_GCS - Verbal Response', 'min_GCS - Verbal Response', 'mean_GCS - Verbal Response', \n",
    "    'mean_GCS - Motor Response', 'min_GCS - Motor Response', 'max_GCS - Motor Response', \n",
    "    'mean_GCS - Eye Opening', 'max_GCS - Eye Opening', 'min_GCS - Eye Opening', \n",
    "    'max_Activity / Mobility (JH-HLM)', 'min_Activity / Mobility (JH-HLM)', \n",
    "    'mean_Activity / Mobility (JH-HLM)', 'min_Respiratory Rate', 'max_Respiratory Rate', \n",
    "    'mean_Respiratory Rate', 'mean_Heart Rate', 'mean_O2 saturation pulseoxymetry', \n",
    "    'max_O2 saturation pulseoxymetry', 'max_Heart Rate', 'min_O2 saturation pulseoxymetry', \n",
    "    'min_Heart Rate', 'dod', 'outtime'\n",
    "]\n",
    "\n",
    "historical = historical.drop(columns=cols_to_drop)\n",
    "contemporary = contemporary.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with missing diagnoses\n",
    "historical = historical.dropna(subset=['icd_code', 'icd_version'])\n",
    "contemporary = contemporary.dropna(subset=['icd_code', 'icd_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_impute = [\n",
    "    'min_Phosphate', 'max_Phosphate', 'mean_Phosphate',\n",
    "    'mean_Calcium, Total', 'max_Calcium, Total', 'min_Calcium, Total',\n",
    "    'mean_Magnesium', 'min_Magnesium', 'max_Magnesium',\n",
    "    'max_RDW', 'min_RDW', 'mean_RDW',\n",
    "    'mean_MCH', 'max_MCH', 'min_MCH',\n",
    "    'mean_MCV', 'max_MCV', 'min_MCV',\n",
    "    'min_Red Blood Cells', 'mean_Red Blood Cells', 'max_Red Blood Cells',\n",
    "    'min_MCHC', 'mean_MCHC', 'max_MCHC',\n",
    "    'max_White Blood Cells', 'mean_White Blood Cells', 'min_White Blood Cells',\n",
    "    'max_Hemoglobin', 'mean_Hemoglobin', 'min_Hemoglobin',\n",
    "    'min_Platelet Count', 'mean_Platelet Count', 'max_Platelet Count',\n",
    "    'min_Glucose', 'max_Glucose', 'mean_Glucose',\n",
    "    'mean_Anion Gap', 'min_Anion Gap', 'max_Anion Gap',\n",
    "    'max_Bicarbonate', 'min_Bicarbonate', 'mean_Bicarbonate',\n",
    "    'mean_Hematocrit', 'min_Hematocrit', 'max_Hematocrit',\n",
    "    'max_Chloride', 'min_Chloride', 'mean_Chloride',\n",
    "    'max_Sodium', 'mean_Sodium', 'min_Sodium',\n",
    "    'mean_Urea Nitrogen', 'min_Urea Nitrogen', 'max_Urea Nitrogen',\n",
    "    'mean_Creatinine', 'min_Creatinine', 'max_Creatinine',\n",
    "    'max_Potassium', 'min_Potassium', 'mean_Potassium'\n",
    "]\n",
    "\n",
    "# imputing missing values with mean to not change the existing distributions\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "historical[cols_to_impute] = imputer.fit_transform(historical[cols_to_impute])\n",
    "contemporary[cols_to_impute] = imputer.transform(contemporary[cols_to_impute])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_readmission_target(df):\n",
    "    \"\"\"\n",
    "    Calculates the 30-day readmission column for a given dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    #create temp df to calulate the target variable\n",
    "    temp_df = df[['subject_id', 'hadm_id', 'admittime', 'dischtime']].copy()\n",
    "\n",
    "    # De-duplicate the temporary dataframe to handle multiple events per admission\n",
    "    temp_df = temp_df.drop_duplicates()\n",
    "    \n",
    "    # Ensure date columns are datetime objects\n",
    "    temp_df['admittime'] = pd.to_datetime(temp_df['admittime'])\n",
    "    temp_df['dischtime'] = pd.to_datetime(temp_df['dischtime'])\n",
    "\n",
    "    # Sort by patient and admission time to ensure correct chronological order\n",
    "    temp_df = temp_df.sort_values(by=['subject_id', 'admittime'])\n",
    "\n",
    "    # For each patient, find the timestamp of their next admission\n",
    "    temp_df['next_admission_time'] = temp_df.groupby('subject_id')['admittime'].shift(-1) #groups data by a single patient, only focuses on the admit time\n",
    "\n",
    "    # Calculate the time in days from discharge to the next admission\n",
    "    temp_df['days_to_next_admission'] = (temp_df['next_admission_time'] - temp_df['dischtime']).dt.days\n",
    "\n",
    "    # Create the binary target variable\n",
    "    temp_df['readmission_30d'] = (temp_df['days_to_next_admission'] <= 30).astype(int)\n",
    "\n",
    "    # Merge just the new target column back into the original dataframe\n",
    "    df = pd.merge(df, temp_df[['hadm_id', 'readmission_30d']], on='hadm_id', how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "historical = create_readmission_target(historical)\n",
    "contemporary = create_readmission_target(contemporary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "cols_to_drop = ['admittime', 'dischtime', 'anchor_year']\n",
    "\n",
    "historical = historical.drop(columns=cols_to_drop)\n",
    "contemporary = contemporary.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical.to_csv(f'{data_path}/historical_cohort.csv.gz', index=False, compression='gzip')\n",
    "contemporary.to_csv(f'{data_path}/contemporary_cohort.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contemporary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
