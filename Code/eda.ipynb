{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\aaani\\OneDrive - Birmingham City University\\Postgrad\\Dissertation\\Data' #path to the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to keep, this is done before loading the data to save on space complexity \n",
    "\n",
    "admissions_cols = ['subject_id', 'hadm_id', 'admittime', 'dischtime', 'race', 'hospital_expire_flag']\n",
    "diagnoses_cols = ['subject_id', 'hadm_id', 'icd_code', 'icd_version']\n",
    "d_icd_diagnoses_cols = ['icd_code', 'icd_version']\n",
    "d_labitems_cols = ['itemid', 'label']\n",
    "labevents_cols = ['subject_id', 'hadm_id', 'itemid', 'charttime', 'valuenum']\n",
    "\n",
    "icustays_cols = ['subject_id', 'hadm_id', 'stay_id', 'outtime', 'los']\n",
    "chartevents_cols = ['subject_id', 'hadm_id', 'itemid', 'charttime', 'valuenum', 'stay_id']\n",
    "d_items_cols = ['itemid', 'label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising dfs\n",
    "\n",
    "#hospital\n",
    "admissions = pd.read_csv(f'{data_path}/admissions.csv.gz', usecols=admissions_cols)\n",
    "patients = pd.read_csv(f'{data_path}/patients.csv.gz')\n",
    "diagnoses = pd.read_csv(f'{data_path}/diagnoses_icd.csv.gz', usecols=diagnoses_cols)\n",
    "d_icd_diagnoses = pd.read_csv(f'{data_path}/d_icd_diagnoses.csv.gz', usecols=d_icd_diagnoses_cols)\n",
    "d_labitems = pd.read_csv(f'{data_path}/d_labitems.csv.gz', usecols=d_labitems_cols)\n",
    "lab = pd.read_csv(f'{data_path}/labevents_last24h.csv.gz', usecols=labevents_cols, parse_dates=['charttime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#icu\n",
    "icustays = pd.read_csv(f'{data_path}/icustays.csv.gz', usecols=icustays_cols, parse_dates=['outtime'])\n",
    "chartevents = pd.read_csv(f'{data_path}/chartevents_last24h.csv.gz', parse_dates=['charttime'], usecols=chartevents_cols)\n",
    "d_items = pd.read_csv(f'{data_path}/d_items.csv.gz', usecols=d_items_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 10_000_000\n",
    "\n",
    "# This ensures the header is written only once\n",
    "first_chunk = True\n",
    "\n",
    "# a loop that reads the labevents file in chunks\n",
    "for chunk in pd.read_csv(f'{data_path}/labevents.csv.gz', chunksize=chunk_size, parse_dates=['charttime']):\n",
    "    \n",
    "    # Merge the chunk with admissions to get the 'dischtime' for each lab event\n",
    "    chunk_with_dischtime = pd.merge(chunk, admissions, on=['subject_id', 'hadm_id'], how='inner') # this is so we can calculate the final 24 hr\n",
    "\n",
    "    # Calculate the time difference in hours from the lab event to hospital discharge\n",
    "    time_delta_hours = (chunk_with_dischtime['dischtime'] - chunk_with_dischtime['charttime']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Filter the chunk to keep only labs from the last 24 hours before discharge\n",
    "    filtered_chunk = chunk_with_dischtime[(time_delta_hours >= 0) & (time_delta_hours <= 24)]\n",
    "    \n",
    "    # If the filtered chunk contains any data, save it to our new CSV file\n",
    "    if not filtered_chunk.empty:\n",
    "        if first_chunk:\n",
    "            # For the first chunk, create a new file and write the header\n",
    "            filtered_chunk.to_csv('labevents_last24h.csv', index=False, mode='w', header=True)\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            # For all other chunks, append to the file without the header\n",
    "            filtered_chunk.to_csv('labevents_last24h.csv', index=False, mode='a', header=False)\n",
    "            \n",
    "    print(f\"Processed a chunk of {chunk_size} rows...\")\n",
    "\n",
    "# smaller file created!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 10_000_000 # 10 million rows at a time\n",
    "\n",
    "# This flag ensures we only write the header once\n",
    "first_chunk = True\n",
    "\n",
    "# a loop that reads the chartevents file in chunks\n",
    "for chunk in pd.read_csv(f'{data_path}/chartevents.csv.gz', chunksize=chunk_size, parse_dates=['charttime']):\n",
    "    \n",
    "    # Merge the chunk with icustays to get the 'outtime' for each event\n",
    "    chunk_with_outtime = pd.merge(chunk, icustays, on=['subject_id', 'hadm_id', 'stay_id'], how='inner') # this is so we can calculate the final 24 hr\n",
    "    \n",
    "    # Calculate the time difference in hours from the event to discharge\n",
    "    time_delta_hours = (chunk_with_outtime['outtime'] - chunk_with_outtime['charttime']).dt.total_seconds() / 3600\n",
    "\n",
    "    # Filter the chunk to keep only events from the last 24 hours before discharge\n",
    "    filtered_chunk = chunk_with_outtime[(time_delta_hours >= 0) & (time_delta_hours <= 24)]\n",
    "    \n",
    "    # If the filtered chunk contains any data, save it to the new CSV file\n",
    "    if not filtered_chunk.empty:\n",
    "        if first_chunk:\n",
    "            # For the first chunk, create a new .gz file and write the header\n",
    "            filtered_chunk.to_csv(\n",
    "                'chartevents_last24h.csv.gz', \n",
    "                index=False, \n",
    "                mode='w', \n",
    "                header=True, \n",
    "                compression='gzip'\n",
    "            )\n",
    "            first_chunk = False\n",
    "    else:\n",
    "        # For all other chunks, add to the file without the header\n",
    "        filtered_chunk.to_csv(\n",
    "            'chartevents_last24h.csv.gz', \n",
    "            index=False, \n",
    "            mode='a', \n",
    "            header=False, \n",
    "            compression='gzip'\n",
    "        )\n",
    "            \n",
    "    print(f\"Processed a chunk of {chunk_size} rows...\")\n",
    "\n",
    "# compressed file created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop values where valuenum is null\n",
    "lab= lab.dropna(subset=['valuenum'])\n",
    "chartevents = chartevents.dropna(subset=['valuenum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged patients to multiple table links; patient to their diagnoses, lab results, and ICU stays etc\n",
    "\n",
    "# used left joins on all so no data is lost\n",
    "\n",
    "# merged patients with their hospital admissions\n",
    "merged = pd.merge(admissions, patients, on='subject_id', how='left')\n",
    "\n",
    "# merge icd codes with their descriptions\n",
    "diag = pd.merge(diagnoses, d_icd_diagnoses, on=['icd_code', 'icd_version'], how='left')\n",
    "merged = pd.merge(merged, diag, on= ['subject_id' , 'hadm_id'], how='left') #back to the main merge\n",
    "\n",
    "# icu stay info\n",
    "merged = pd.merge(merged, icustays, on=['subject_id' , 'hadm_id'], how='left')\n",
    "\n",
    "# add labels to lab events\n",
    "lab = pd.merge(lab, d_labitems, on='itemid', how='left')\n",
    "chartevents = pd.merge(chartevents, d_items, on='itemid', how='left')\n",
    "\n",
    "# filtered to top 20 to reduce size\n",
    "\n",
    "top_20_labs = lab['label'].value_counts().nlargest(20).index #20 most common lab tests\n",
    "lab_filtered = lab[lab['label'].isin(top_20_labs)] #new fd that onlt has the top 20 lab results - smaller size\n",
    "\n",
    "lab_features = lab_filtered.groupby(['hadm_id', 'label'])['valuenum'].agg(['mean', 'min', 'max']).unstack(level='label') #group\n",
    "lab_features.columns = ['_'.join(col).strip() for col in lab_features.columns.values]\n",
    "lab_features = lab_features.reset_index()\n",
    "\n",
    "top_20_charts = chartevents['label'].value_counts().nlargest(20).index # 20 most common chart events\n",
    "charts_filtered = chartevents[chartevents['label'].isin(top_20_charts)]\n",
    "\n",
    "chartevents_features = charts_filtered.groupby(['stay_id', 'label'])['valuenum'].agg(['mean', 'min', 'max']).unstack(level='label')\n",
    "\n",
    "chartevents_features.columns = ['_'.join(col).strip() for col in chartevents_features.columns.values]\n",
    "chartevents_features = chartevents_features.reset_index()\n",
    "\n",
    "merged = pd.merge(merged, lab_features, on=['hadm_id'], how='left')\n",
    "merged = pd.merge(merged, chartevents_features, on=['stay_id'], how='left')\n",
    "\n",
    "merged.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('final_dataset.csv.gz', index=False, compression='gzip') #saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_info = pd.read_csv(f'{data_path}/final_dataset.csv.gz', nrows=1)\n",
    "\n",
    "\n",
    "df = pd.read_csv(f'{data_path}/final_dataset.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataset that removes duplicate patients, for analysis\n",
    "unique = df.drop_duplicates(subset=['subject_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "sns.histplot(unique['anchor_age'], bins=30, kde=True, color='skyblue')\n",
    "\n",
    "\n",
    "plt.title('Distribution of Patient Age at Admission in MIMIC-IV', fontsize=16)\n",
    "plt.xlabel('Age at Admission', fontsize=12)\n",
    "plt.ylabel('Number of Admissions', fontsize=12)\n",
    "\n",
    "# Saving the plot as an image file \n",
    "plt.savefig('age_distribution.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying unique anchor years\n",
    "unique_anchor_years = unique['anchor_year_group'].unique()\n",
    "unique_anchor_years.sort()\n",
    "print(\"Unique Anchor Years:\", unique_anchor_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_groups = ['2008 - 2010', '2011 - 2013', '2014 - 2016']\n",
    "contemporary_groups = ['2017 - 2019', '2020 - 2022']\n",
    "\n",
    "historical = unique[unique['anchor_year_group'].isin(historical_groups)]\n",
    "contemporary = unique[unique['anchor_year_group'].isin(contemporary_groups)]\n",
    "\n",
    "historical_age_distribution = historical['anchor_age'].describe()\n",
    "contemporary_age_distribution = contemporary['anchor_age'].describe()\n",
    "\n",
    "print(\"Historical Age Distribution:\\n\", historical_age_distribution)\n",
    "print(\"\\nContemporary Age Distribution:\\n\", contemporary_age_distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a figure for the plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot the distribution of age for the historical cohort\n",
    "sns.kdeplot(historical['anchor_age'], label='Historical Cohort (2008-2016)', color='blue', fill=True, alpha=0.5)\n",
    "\n",
    "# Plot the distribution of age for the contemporary cohort on the same axes\n",
    "sns.kdeplot(contemporary['anchor_age'], label='Contemporary Cohort (2017-2022)', color='green', fill=True, alpha=0.5)\n",
    "\n",
    "# Add titles, labels, and a legend\n",
    "plt.title('Comparison of Patient Age Distribution: Historical vs. Contemporary', fontsize=16)\n",
    "plt.xlabel('Age at Admission', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('age_distribution_comparison.png')\n",
    "\n",
    "#This is important as it provided visual evidence of a data drift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the unique race categories\n",
    "unique_race = unique['race'].unique()\n",
    "unique_race.sort()\n",
    "print(\"Unique Race Categories:\", unique_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for the race categories for better readability\n",
    "\n",
    "race_mapping = {\n",
    "    'ASIAN - ASIAN INDIAN': 'ASIAN',\n",
    "    'ASIAN - CHINESE': 'ASIAN',\n",
    "    'ASIAN - KOREAN': 'ASIAN',\n",
    "    'ASIAN - SOUTH EAST ASIAN': 'ASIAN',\n",
    "    'BLACK/AFRICAN': 'BLACK',\n",
    "    'BLACK/AFRICAN AMERICAN': 'BLACK',\n",
    "    'BLACK/CAPE VERDEAN': 'BLACK',\n",
    "    'BLACK/CARIBBEAN ISLAND': 'BLACK',\n",
    "    'HISPANIC OR LATINO': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - CENTRAL AMERICAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - COLUMBIAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - CUBAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - DOMINICAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - GUATEMALAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - HONDURAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - MEXICAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - PUERTO RICAN': 'HISPANIC/LATINO',\n",
    "    'HISPANIC/LATINO - SALVADORAN': 'HISPANIC/LATINO',\n",
    "    'WHITE - BRAZILIAN': 'WHITE',\n",
    "    'WHITE - EASTERN EUROPEAN': 'WHITE',\n",
    "    'WHITE - OTHER EUROPEAN': 'WHITE',\n",
    "    'WHITE - RUSSIAN': 'WHITE',\n",
    "    'PORTUGUESE': 'WHITE',\n",
    "    'SOUTH AMERICAN': 'HISPANIC/LATINO',\n",
    "    'UNABLE TO OBTAIN': 'OTHER/UNKNOWN',\n",
    "    'UNKNOWN': 'OTHER/UNKNOWN',\n",
    "    'PATIENT DECLINED TO ANSWER': 'OTHER/UNKNOWN',\n",
    "    'OTHER': 'OTHER/UNKNOWN',\n",
    "    'AMERICAN INDIAN/ALASKA NATIVE': 'OTHER/UNKNOWN',\n",
    "    'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER': 'OTHER/UNKNOWN',\n",
    "    'MULTIPLE RACE/ETHNICITY': 'OTHER/UNKNOWN'\n",
    "}\n",
    "\n",
    "\n",
    "unique['race_grouped'] = unique['race'].replace(race_mapping)\n",
    "print(unique['race_grouped'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = unique[unique['anchor_year_group'].isin(historical_groups)]\n",
    "contemporary = unique[unique['anchor_year_group'].isin(contemporary_groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage distribution for the historical cohort\n",
    "historical_race_dist = historical['race_grouped'].value_counts(normalize=True).mul(100).rename('percentage').reset_index()\n",
    "historical_race_dist['Cohort'] = 'Historical (2008-2016)'\n",
    "\n",
    "# Calculate the percentage distribution for the contemporary cohort\n",
    "contemporary_race_dist = contemporary['race_grouped'].value_counts(normalize=True).mul(100).rename('percentage').reset_index()\n",
    "contemporary_race_dist['Cohort'] = 'Contemporary (2017-2022)'\n",
    "\n",
    "\n",
    "combined_race_dist = pd.concat([historical_race_dist, contemporary_race_dist])\n",
    "\n",
    "# Visualisation \n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create the bar plot\n",
    "barplot = sns.barplot(data=combined_race_dist, x='race_grouped', y='percentage', hue='Cohort', palette='viridis')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Comparison of Patient Race Distribution: Historical vs. Contemporary', fontsize=16)\n",
    "plt.xlabel('Race', fontsize=12)\n",
    "plt.ylabel('Percentage of Patients (%)', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('race_distribution_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage distribution for the cohorta\n",
    "hist_gender_dist = historical['gender'].value_counts(normalize=True).mul(100).rename('percentage').reset_index()\n",
    "hist_gender_dist['Cohort'] = 'Historical (2008-2016)'\n",
    "\n",
    "cont_gender_dist = contemporary['gender'].value_counts(normalize=True).mul(100).rename('percentage').reset_index()\n",
    "cont_gender_dist['Cohort'] = 'Contemporary (2017-2022)'\n",
    "\n",
    "# Combine the two distributions into a single DataFrame for plotting\n",
    "combined_gender_dist = pd.concat([hist_gender_dist, cont_gender_dist])\n",
    "\n",
    "\n",
    "# visualisation \n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create the bar plot\n",
    "barplot = sns.barplot(\n",
    "    data=combined_gender_dist, \n",
    "    x='gender', \n",
    "    y='percentage', \n",
    "    hue='Cohort',\n",
    "    palette='magma'\n",
    ")\n",
    "\n",
    "for p in barplot.patches:\n",
    "    if p.get_height() > 0:\n",
    "        barplot.annotate(f'{p.get_height():.1f}%',           # % formatted to one decimal place\n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), #  coordinates of the text\n",
    "                    ha='center', va='center',          # center alignment\n",
    "                    xytext=(0, 9),                     # put text slightly above the bar\n",
    "                    textcoords='offset points',\n",
    "                    fontsize=12)\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.) # Move the legend outside the plot area\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Comparison of Patient Gender Distribution by Cohort', fontsize=16)\n",
    "plt.xlabel('Gender', fontsize=12)\n",
    "plt.ylabel('Percentage of Patients (%)', fontsize=12)\n",
    "plt.xticks(ticks=['F', 'M'], labels=['Female', 'Male']) \n",
    "\n",
    "\n",
    "plt.savefig('Images/gender_distribution_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical['Cohort'] = 'Historical (2008-2016)'\n",
    "contemporary['Cohort'] = 'Contemporary (2017-2022)'\n",
    "\n",
    "# Combine the two patient-level dataframes\n",
    "combined_df = pd.concat([historical, contemporary])\n",
    "\n",
    "# Map the hospital_expire_flag to readable labels for the legend\n",
    "combined_df['Outcome'] = combined_df['hospital_expire_flag'].map({0: 'Survived', 1: 'Died'})\n",
    "\n",
    "\n",
    "# two subplots side-by-side to compare the cohorts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8), sharey=True)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot for Historical Cohort\n",
    "sns.histplot(\n",
    "    data=combined_df[combined_df['Cohort'] == 'Historical (2008-2016)'],\n",
    "    x='race_grouped',\n",
    "    hue='Outcome',\n",
    "    multiple='fill',  # stacked bar\n",
    "    stat='percent',\n",
    "    shrink=0.8,\n",
    "    ax=axes[0],\n",
    "    palette={'Survived': 'skyblue', 'Died': 'coral'}\n",
    ")\n",
    "axes[0].set_title('Historical Cohort (2008-2016)', fontsize=14)\n",
    "axes[0].set_xlabel('Race', fontsize=12)\n",
    "axes[0].set_ylabel('Percentage of Patients (%)', fontsize=12)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot for Contemporary Cohort\n",
    "sns.histplot(\n",
    "    data=combined_df[combined_df['Cohort'] == 'Contemporary (2017-2022)'],\n",
    "    x='race_grouped',\n",
    "    hue='Outcome',\n",
    "    multiple='fill',\n",
    "    stat='percent',\n",
    "    shrink=0.8,\n",
    "    ax=axes[1],\n",
    "    palette={'Survived': 'skyblue', 'Died': 'coral'}\n",
    ")\n",
    "axes[1].set_title('Contemporary Cohort (2017-2022)', fontsize=14)\n",
    "axes[1].set_xlabel('Race', fontsize=12)\n",
    "axes[1].set_ylabel('') # Hide y-axis label for the second plot for clarity\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add Percentage Labels to Both Plots\n",
    "for ax in axes:\n",
    "    for container in ax.containers:\n",
    "        # Get the labels for each bar in the container\n",
    "        labels = [f'{h.get_height()*100:.1f}%' for h in container]\n",
    "        ax.bar_label(container, labels=labels, label_type='center', fontsize=10, color='black', weight='bold')\n",
    "\n",
    "\n",
    "# titles\n",
    "fig.suptitle('In-Hospital Mortality Rate by Race and Cohort', fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make room for suptitle\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('Images/outcome_by_race_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sample = df.sample(n=1000, random_state=1)\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(df_sample.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Data Heatmap (Sample of 1000 Rows)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = [\n",
    "    # ICU Vitals and Stays\n",
    "    'los', \n",
    "    'mean_Heart Rate', \n",
    "    'mean_Respiratory Rate', \n",
    "    'mean_Glucose', \n",
    "    'mean_Temperature Fahrenheit',\n",
    "    \n",
    "    # Key Lab Values\n",
    "    'mean_Creatinine',\n",
    "    'mean_Potassium',\n",
    "    'mean_Sodium',\n",
    "    'mean_White Blood Cells',\n",
    "    'mean_Hemoglobin',\n",
    "    'mean_Platelet Count'\n",
    "]\n",
    "\n",
    "corr_matrix = df[top_features].corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool)) # to only show bottom half\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", mask=mask)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('Images/feature_correlation_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create the boxplot \n",
    "sns.boxplot(\n",
    "    data=df, \n",
    "    x='hospital_expire_flag', \n",
    "    y='los', \n",
    "    hue='hospital_expire_flag', # Assign the x-variable to hue\n",
    "    palette=\"viridis\",\n",
    "    legend=False # Hides legend\n",
    ")\n",
    "\n",
    "# Change the x-axis labels\n",
    "plt.xticks(ticks=[0, 1], labels=['Survived', 'Died'], fontsize=12)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('In-Hospital Mortality is Associated with Longer Stays', fontsize=16)\n",
    "plt.xlabel('Patient Outcome', fontsize=14)\n",
    "plt.ylabel('Length of Stay in Days', fontsize=14)\n",
    "\n",
    "# Zoom in on the y-axis to show box plots better\n",
    "plt.ylim(0, 20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('Images/in_hospital_mortality_longer_stays.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
